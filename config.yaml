# TriangulateAI Configuration File

# Image settings
image_size: 256
triangles_n: 100

# Model architecture
model:
  encoder_depth: 5
  channels_base: 64
  channels_progression: [64, 128, 256, 512, 512]
  hidden_dim: 512
  fc_hidden_dim: 1024

# Loss weights
loss:
  alpha: 1.0    # Perceptual (VGG) loss weight
  beta: 0.1     # L1 pixel loss weight
  gamma: 0.05   # LPIPS loss weight
  vgg_layers: ['conv1_2', 'conv2_2', 'conv3_4', 'conv4_4']

# Optimizer settings
optimizer:
  type: 'AdamW'
  lr: 1e-4
  betas: [0.9, 0.95]
  weight_decay: 1e-4

# Training settings
training:
  batch_size: 4
  epochs: 50
  save_interval: 5
  warmup_ratio: 0.01  # 1% of total steps
  mixed_precision: true
  gradient_clip: 1.0
  device: 'cuda:0'

# Data settings
data:
  train_split: 0.9
  val_split: 0.1
  augmentation:
    random_flip: true
    hsv_jitter: 0.1
  num_workers: 4
  pin_memory: true

# Logging settings
logging:
  wandb_project: 'triangulate_ai'
  wandb_entity: null  # Set your W&B entity
  log_interval: 50    # Log every N iterations
  sample_interval: 1  # Save sample images every N epochs

# Paths
paths:
  data_dir: 'data'
  checkpoint_dir: 'checkpoints'
  output_dir: 'outputs'
  lmdb_path: 'data/images.lmdb'

# Inference settings
inference:
  batch_size: 1
  device: 'cuda:0'

# Evaluation settings
evaluation:
  metrics: ['lpips', 'ssim', 'psnr']
  batch_size: 8